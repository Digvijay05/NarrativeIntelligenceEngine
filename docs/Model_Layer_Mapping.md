# ML Library â†’ Backend Layer Mapping

## Forensic Architecture Alignment

This document maps selected ML libraries to the 6-layer backend architecture, with explicit **fence posts** marking where machine learning must stop.

> [!CAUTION]
> **Constitutional Boundary**: ML computes geometry and surfaces uncertainty. It NEVER decides, infers, ranks, or predicts. All ML outputs cross layer boundaries as **immutable contracts** only.

---

## Architecture Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ML FENCE POST LEGEND                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸš« = ML FORBIDDEN (inference would violate forensic integrity)            â”‚
â”‚  âš™ï¸  = ML COMPUTES (coordinate transforms, geometry, alignment)             â”‚
â”‚  ğŸ“Š = UNCERTAINTY SURFACED (distributions, not point estimates)             â”‚
â”‚  ğŸ“¤ = OUTPUT CONTRACT (immutable, crosses to next layer)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer-by-Layer ML Mapping

### Layer 1: Ingestion

**Purpose**: Raw data capture from external sources  
**ML Allowed**: âŒ NONE

| What Happens | ML Role | Fence Post |
|--------------|---------|------------|
| HTTP fetch | None | ğŸš« No preprocessing |
| Raw bytes storage | None | ğŸš« No filtering |
| Provenance tagging | None | ğŸš« No quality scoring |

**Constitutional Rule**: Ingestion is a **tape recorder**. It captures exactly what arrives, when. No ML touches this layer.

**Output Contract**: `RawIngestionEvent` (verbatim payload, hash, timestamp, tier)

---

### Layer 2: Normalization

**Purpose**: Transform raw events into canonical fragments  
**ML Allowed**: âš™ï¸ Coordinate transforms only

#### Library Mapping

| Library | Function | What It Computes | Fence Post |
|---------|----------|------------------|------------|
| **sentence-transformers** | Embedding generation | Vector coordinates in semantic space | ğŸš« No similarity thresholds that imply "same meaning" |
| **gensim** (TF-IDF) | Term weighting | Frequency-based coordinates | ğŸš« No topic classification |

#### Detailed Constraints

```python
# âœ… ALLOWED: Compute embedding as coordinate transform
embedding = model.encode(text)  # Just a vector

# ğŸš« FORBIDDEN: Threshold that implies semantic equivalence
if cosine_sim(a, b) > 0.8:  # Who decided 0.8 means "same"?
    return "duplicate"      # FORBIDDEN - this is inference
    
# âœ… ALLOWED: Return raw similarity as data
return {
    "similarity_score": cosine_sim(a, b),  # Surface the number
    "threshold_applied": None              # No decision made
}
```

#### ML Stops Here

| Computation | Status |
|-------------|--------|
| Vector embedding | âš™ï¸ Allowed |
| Cosine distance | âš™ï¸ Allowed |
| Duplicate decision | ğŸš« FORBIDDEN |
| Topic classification | ğŸš« FORBIDDEN |
| Entity resolution | ğŸš« FORBIDDEN |

**Output Contract**: `NormalizedFragment` (with `DuplicateInfo.status = UNDETERMINED` if ML can't decide without inference)

---

### Layer 3: Core Narrative State Engine

**Purpose**: Thread construction, lifecycle, divergence detection  
**ML Allowed**: âš™ï¸ Geometry and alignment only

#### Library Mapping

| Library | Function | What It Computes | Fence Post |
|---------|----------|------------------|------------|
| **NetworkX** | Graph construction | Topology (nodes, edges) | ğŸš« No centrality rankings |
| **tslearn** (DTW) | Timeline alignment | Temporal distance between sequences | ğŸš« No "earlier is more authoritative" |
| **hdbscan** | Fragment grouping | Cluster membership + noise | ğŸš« No "best cluster" selection |
| **hmmlearn** | State labeling | Transition probabilities | ğŸš« No prediction of next state |

#### Detailed Constraints

##### NetworkX (Graph Topology)

```python
# âœ… ALLOWED: Build co-occurrence graph
G = nx.Graph()
G.add_edge(fragment_a, fragment_b, weight=overlap_score)

# âœ… ALLOWED: Detect connected components (structural)
components = list(nx.connected_components(G))

# ğŸš« FORBIDDEN: PageRank or centrality (implies importance)
important = nx.pagerank(G)  # FORBIDDEN

# ğŸš« FORBIDDEN: Shortest path as "narrative flow"
path = nx.shortest_path(G, a, b)  # Only if not interpreted as causality
```

##### tslearn (Dynamic Time Warping)

```python
# âœ… ALLOWED: Compute alignment distance
distance = dtw(timeline_a, timeline_b)

# âœ… ALLOWED: Return alignment path (which points matched)
path = dtw_path(timeline_a, timeline_b)

# ğŸš« FORBIDDEN: "Timeline A is more complete"
completeness = score_completeness(timeline_a)  # FORBIDDEN

# ğŸš« FORBIDDEN: "Source X reported first" as authority
authority = first_reporter_bonus(timeline_a)  # FORBIDDEN
```

##### hdbscan (Clustering)

```python
# âœ… ALLOWED: Cluster with explicit noise
clusterer = hdbscan.HDBSCAN(min_cluster_size=3)
labels = clusterer.fit_predict(embeddings)

# âœ… REQUIRED: Preserve noise label (-1) as UNASSIGNED
unassigned = [i for i, l in enumerate(labels) if l == -1]

# ğŸš« FORBIDDEN: Force all fragments into clusters
# ğŸš« FORBIDDEN: "Cluster 0 is the main narrative"
# ğŸš« FORBIDDEN: Merge noise into nearest cluster
```

##### hmmlearn (State Machines)

```python
# âœ… ALLOWED: Label current lifecycle state
state_probs = model.predict_proba(observations)

# âœ… REQUIRED: Surface distribution, not argmax
return {
    "EMERGING": state_probs[0],
    "ACTIVE": state_probs[1],
    "DORMANT": state_probs[2]
}  # Let frontend show uncertainty

# ğŸš« FORBIDDEN: Predict next state
# ğŸš« FORBIDDEN: "Thread will terminate in 3 days"
```

#### ML Stops Here

| Computation | Status |
|-------------|--------|
| Graph construction | âš™ï¸ Allowed |
| DTW alignment | âš™ï¸ Allowed |
| Cluster membership | âš™ï¸ Allowed |
| State probability | ğŸ“Š Uncertainty surfaced |
| Importance ranking | ğŸš« FORBIDDEN |
| Prediction | ğŸš« FORBIDDEN |
| Causality | ğŸš« FORBIDDEN |

**Output Contract**: `ThreadStateSnapshot` (with `divergence_reason` as observation, not judgment)

---

### Layer 4: Temporal Storage

**Purpose**: Append-only versioned persistence  
**ML Allowed**: âŒ NONE

| What Happens | ML Role | Fence Post |
|--------------|---------|------------|
| Version creation | None | ğŸš« No compression via summarization |
| Timeline indexing | None | ğŸš« No importance-based pruning |
| Snapshot storage | None | ğŸš« No "stale" detection |

**Constitutional Rule**: Storage is a **geological record**. Every version is preserved exactly as emitted. No ML touches this layer.

**Output Contract**: `VersionedSnapshot`, `Timeline`

---

### Layer 5: Query

**Purpose**: Read-only access to stored data  
**ML Allowed**: âš™ï¸ Search and retrieval geometry only

#### Library Mapping

| Library | Function | What It Computes | Fence Post |
|---------|----------|------------------|------------|
| **sentence-transformers** | Query embedding | Vector for similarity search | ğŸš« No "most relevant" ranking |
| **PyTorch** | Distance computation | Vectorized distance metrics | ğŸš« No learned ranking |

#### Detailed Constraints

```python
# âœ… ALLOWED: Embed query, return K nearest
query_vec = model.encode(query)
results = index.search(query_vec, k=100)

# âœ… REQUIRED: Return all K with distances (no filtering)
return [
    {"fragment_id": id, "distance": d}
    for id, d in zip(results.ids, results.distances)
]

# ğŸš« FORBIDDEN: Filter by learned threshold
# ğŸš« FORBIDDEN: Re-rank by "relevance"
# ğŸš« FORBIDDEN: Collapse near-duplicates in results
```

#### ML Stops Here

| Computation | Status |
|-------------|--------|
| Query embedding | âš™ï¸ Allowed |
| Distance-based retrieval | âš™ï¸ Allowed |
| K-nearest neighbors | âš™ï¸ Allowed (unfiltered) |
| Relevance ranking | ğŸš« FORBIDDEN |
| Result summarization | ğŸš« FORBIDDEN |

**Output Contract**: `QueryResult` (with raw distances, not relevance scores)

---

### Layer 6: Observability

**Purpose**: Logging, metrics, replay, lineage  
**ML Allowed**: ğŸ“Š Anomaly detection (uncertainty surfaced only)

#### Library Mapping

| Library | Function | What It Computes | Fence Post |
|---------|----------|------------------|------------|
| **PyMC** | Distribution modeling | Posterior distributions | ğŸš« No point estimates |
| **ArviZ** | Trace inspection | Diagnostic visualizations | ğŸ“Š Surface uncertainty |

#### Detailed Constraints

```python
# âœ… ALLOWED: Compute distribution over normal behavior
with pm.Model():
    rate = pm.Exponential("ingestion_rate", lam=1/expected_rate)
    obs = pm.Poisson("observed", mu=rate, observed=data)
    trace = pm.sample()

# âœ… REQUIRED: Report full posterior, not point estimate
return {
    "ingestion_rate": {
        "mean": trace["ingestion_rate"].mean(),
        "std": trace["ingestion_rate"].std(),
        "hdi_3%": az.hdi(trace, hdi_prob=0.94)["ingestion_rate"][0],
        "hdi_97%": az.hdi(trace, hdi_prob=0.94)["ingestion_rate"][1]
    }
}

# ğŸš« FORBIDDEN: "Ingestion rate is 5.2" (point estimate hides uncertainty)
# ğŸš« FORBIDDEN: "Anomaly detected" (binary decision from continuous distribution)
```

#### ML Stops Here

| Computation | Status |
|-------------|--------|
| Distribution fitting | ğŸ“Š Allowed (surfaces uncertainty) |
| Credible intervals | ğŸ“Š Allowed |
| Trace diagnostics | ğŸ“Š Allowed |
| Anomaly classification | ğŸš« FORBIDDEN |
| Automated alerting | ğŸš« FORBIDDEN |

**Output Contract**: `MetricPoint` (with uncertainty bounds, not binary flags)

---

## Complete Library â†’ Layer Matrix

| Library | L1 Ingestion | L2 Normalization | L3 Core Engine | L4 Storage | L5 Query | L6 Observability |
|---------|:------------:|:----------------:|:--------------:|:----------:|:--------:|:----------------:|
| **PyTorch** | âŒ | âš™ï¸ tensor ops | âš™ï¸ distance | âŒ | âš™ï¸ search | âŒ |
| **sentence-transformers** | âŒ | âš™ï¸ embeddings | âŒ | âŒ | âš™ï¸ query embed | âŒ |
| **gensim** | âŒ | âš™ï¸ TF-IDF | âŒ | âŒ | âŒ | âŒ |
| **NetworkX** | âŒ | âŒ | âš™ï¸ topology | âŒ | âŒ | âŒ |
| **tslearn** | âŒ | âŒ | âš™ï¸ DTW | âŒ | âŒ | âŒ |
| **hdbscan** | âŒ | âŒ | âš™ï¸ clustering | âŒ | âŒ | âŒ |
| **hmmlearn** | âŒ | âŒ | âš™ï¸ states | âŒ | âŒ | âŒ |
| **PyMC** | âŒ | âŒ | âŒ | âŒ | âŒ | ğŸ“Š distributions |
| **ArviZ** | âŒ | âŒ | âŒ | âŒ | âŒ | ğŸ“Š diagnostics |

---

## Known Unknowns (Tracked)

| ID | Unknown | Layer | Mitigation |
|----|---------|-------|------------|
| K1 | Embedding stability under adversarial paraphrasing | L2 | Track embedding drift per source |
| K2 | DTW scaling with high-frequency ingestion | L3 | SAX compression via pyts |
| K3 | Human tolerance for UNASSIGNED fragments | L3/Frontend | UX study required |
| K4 | Absence granularity (signal vs noise) | L3 | Configurable time windows |
| K5 | Posterior distribution computation cost | L6 | Batch sampling, caching |

---

## Anti-Patterns (Explicitly Forbidden)

| Pattern | Why Forbidden | What To Do Instead |
|---------|---------------|-------------------|
| End-to-end LLM fine-tuning | Smuggles inference | Use embeddings as coordinates only |
| Reinforcement learning | Implies reward/preference | Surface options without ranking |
| AutoML / AutoClustering | Opacity violates forensic traceability | Explicit algorithms, logged parameters |
| Threshold-based decisions | Hides uncertainty | Return raw scores, let human/frontend decide |
| Point estimates from posteriors | Hides distribution shape | Return full posterior + HDI |

---

## Implementation Checklist

### Phase 1: Coordinate Transforms (L2)
- [ ] Integrate sentence-transformers for embeddings
- [ ] Add embedding to `NormalizedFragment` as `embedding_vector`
- [ ] Compute pairwise distances, store in `DuplicateInfo.similarity_score`
- [ ] Do NOT set `DuplicateInfo.status` from ML alone

### Phase 2: Graph Topology (L3)
- [ ] Build NetworkX graph from fragment co-occurrence
- [ ] Store graph edges in `ThreadStateSnapshot.relations`
- [ ] Compute connected components for thread candidates
- [ ] Do NOT compute centrality or importance

### Phase 3: Timeline Alignment (L3)
- [ ] Integrate tslearn for DTW alignment
- [ ] Compute alignment distances between source timelines
- [ ] Store alignment path in divergence metadata
- [ ] Do NOT infer "who reported first" as authority

### Phase 4: Clustering (L3)
- [ ] Integrate hdbscan for fragment grouping
- [ ] Preserve noise labels as UNASSIGNED
- [ ] Store cluster probabilities (soft clustering)
- [ ] Do NOT force all fragments into clusters

### Phase 5: Uncertainty Surfacing (L6)
- [ ] Integrate PyMC for observability metrics
- [ ] Compute posterior distributions, not point estimates
- [ ] Store credible intervals in `MetricPoint`
- [ ] Do NOT emit binary anomaly flags

---

## Summary

**ML is instrumentation, not judgment.**

Every library serves as a **probe** that measures geometry, distance, alignment, or distribution. The measurements cross layer boundaries as immutable data. The **interpretation** of those measurements happens in the frontend or by human operatorsâ€”never in the backend.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE FUNDAMENTAL RULE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  If an ML output cannot be serialized as an immutable       â”‚
â”‚  contract without losing information, it is FORBIDDEN.      â”‚
â”‚                                                             â”‚
â”‚  Distributions serialize. Decisions do not.                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
